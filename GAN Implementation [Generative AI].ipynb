{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953739b8",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks - Implementation from scratch\n",
    "---\n",
    "\n",
    "> **For Generating Handwritten Digits**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82455c89",
   "metadata": {},
   "source": [
    "## Importing Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd02afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc94c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x294c08665b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good practice to do, so that the experiment can be replicated identically on any machine\n",
    "torch.manual_seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360be4a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Choosing CPU/GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f1d723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If GPU is available than will use GPU else continue with CPU\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.devie(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ebfbf",
   "metadata": {},
   "source": [
    "---\n",
    "## Cooking the Data for Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0faa71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# .ToTensor() - converts data to a pyTorch Tensor\n",
    "# .Normalize() - converts the range of the tensor Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811974a",
   "metadata": {},
   "source": [
    "---\n",
    "### LOADING the data from torchvision datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1cb106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "root=\".\", train=True, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633aef2c",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e922c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32\n",
    "train_dataLoader = torch.utils.data.DataLoader(\n",
    "train_dataset, batch_sz, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515d231",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967f6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sample_set, mnist_labels = next(iter(train_dataLoader))\n",
    "\n",
    "#for i in range(16):\n",
    "#    axis = plt.subplot(5,5,i+1)\n",
    "#   plt.imshow(real_sample_set[i].reshape(28,28))\n",
    "#    plt.xticks([])\n",
    "#    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfb08f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5659ee",
   "metadata": {},
   "source": [
    "# Discriminator and Generator Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066b219",
   "metadata": {},
   "source": [
    "### Discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23edbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a794b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling Discriminator model to the object & also selecting CPU/GPU\n",
    "\n",
    "discriminator_ = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5ce8b",
   "metadata": {},
   "source": [
    "### Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f37658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, 28, 28)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c54680",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_ = Generator().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0e3f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176238b",
   "metadata": {},
   "source": [
    "## Training the Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3373f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Params\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs_cnt = 50\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# Setting up Optimizer for both the Neural Networks\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator_.parameters(), lr=learning_rate)\n",
    "optimizer_generator = torch.optim.Adam(generator_.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbac5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5c9c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss D.: 0.5205891132354736\n",
      "Epoch: 0 Loss G.: 0.5769919753074646\n",
      "------------------------ Time Elapsed: 1.6337950229644775 seconds ------------------------\n",
      "Epoch: 1 Loss D.: 0.04461481049656868\n",
      "Epoch: 1 Loss G.: 5.167757987976074\n",
      "------------------------ Time Elapsed: 116.05373883247375 seconds ------------------------\n",
      "Epoch: 2 Loss D.: 0.018259791657328606\n",
      "Epoch: 2 Loss G.: 6.160158634185791\n",
      "------------------------ Time Elapsed: 247.20123100280762 seconds ------------------------\n",
      "Epoch: 3 Loss D.: 0.0280546136200428\n",
      "Epoch: 3 Loss G.: 10.527824401855469\n",
      "------------------------ Time Elapsed: 383.5022203922272 seconds ------------------------\n",
      "Epoch: 4 Loss D.: 0.0018875167006626725\n",
      "Epoch: 4 Loss G.: 9.207801818847656\n",
      "------------------------ Time Elapsed: 524.6139590740204 seconds ------------------------\n",
      "Epoch: 5 Loss D.: 0.01979658752679825\n",
      "Epoch: 5 Loss G.: 4.719379901885986\n",
      "------------------------ Time Elapsed: 664.0207996368408 seconds ------------------------\n",
      "Epoch: 6 Loss D.: 0.06245090439915657\n",
      "Epoch: 6 Loss G.: 9.662391662597656\n",
      "------------------------ Time Elapsed: 810.3470168113708 seconds ------------------------\n",
      "Epoch: 7 Loss D.: 0.1839209794998169\n",
      "Epoch: 7 Loss G.: 4.194842338562012\n",
      "------------------------ Time Elapsed: 951.4511270523071 seconds ------------------------\n",
      "Epoch: 8 Loss D.: 0.10940990597009659\n",
      "Epoch: 8 Loss G.: 4.0041046142578125\n",
      "------------------------ Time Elapsed: 1096.8851993083954 seconds ------------------------\n",
      "Epoch: 9 Loss D.: 0.24990993738174438\n",
      "Epoch: 9 Loss G.: 2.4109573364257812\n",
      "------------------------ Time Elapsed: 1239.306548833847 seconds ------------------------\n",
      "Epoch: 10 Loss D.: 0.2122119516134262\n",
      "Epoch: 10 Loss G.: 3.1907901763916016\n",
      "------------------------ Time Elapsed: 1380.266765832901 seconds ------------------------\n",
      "Epoch: 11 Loss D.: 0.31287476420402527\n",
      "Epoch: 11 Loss G.: 2.3612112998962402\n",
      "------------------------ Time Elapsed: 1518.9689106941223 seconds ------------------------\n",
      "Epoch: 12 Loss D.: 0.3738236725330353\n",
      "Epoch: 12 Loss G.: 2.080397367477417\n",
      "------------------------ Time Elapsed: 1658.2032599449158 seconds ------------------------\n",
      "Epoch: 13 Loss D.: 0.3112424612045288\n",
      "Epoch: 13 Loss G.: 1.4070162773132324\n",
      "------------------------ Time Elapsed: 1804.8780744075775 seconds ------------------------\n",
      "Epoch: 14 Loss D.: 0.3855475187301636\n",
      "Epoch: 14 Loss G.: 1.7305488586425781\n",
      "------------------------ Time Elapsed: 1948.204422235489 seconds ------------------------\n",
      "Epoch: 15 Loss D.: 0.29928722977638245\n",
      "Epoch: 15 Loss G.: 1.6616506576538086\n",
      "------------------------ Time Elapsed: 2088.2547545433044 seconds ------------------------\n",
      "Epoch: 16 Loss D.: 0.49516937136650085\n",
      "Epoch: 16 Loss G.: 2.048503875732422\n",
      "------------------------ Time Elapsed: 2229.3034961223602 seconds ------------------------\n",
      "Epoch: 17 Loss D.: 0.4275611639022827\n",
      "Epoch: 17 Loss G.: 1.3160572052001953\n",
      "------------------------ Time Elapsed: 2371.3700289726257 seconds ------------------------\n",
      "Epoch: 18 Loss D.: 0.44811660051345825\n",
      "Epoch: 18 Loss G.: 1.7065696716308594\n",
      "------------------------ Time Elapsed: 2513.103001832962 seconds ------------------------\n",
      "Epoch: 19 Loss D.: 0.3746926486492157\n",
      "Epoch: 19 Loss G.: 1.9835798740386963\n",
      "------------------------ Time Elapsed: 2655.712240934372 seconds ------------------------\n",
      "Epoch: 20 Loss D.: 0.3381910026073456\n",
      "Epoch: 20 Loss G.: 1.5521268844604492\n",
      "------------------------ Time Elapsed: 2799.1832191944122 seconds ------------------------\n",
      "Epoch: 21 Loss D.: 0.4208981990814209\n",
      "Epoch: 21 Loss G.: 1.4717326164245605\n",
      "------------------------ Time Elapsed: 2946.2539932727814 seconds ------------------------\n",
      "Epoch: 22 Loss D.: 0.380881130695343\n",
      "Epoch: 22 Loss G.: 1.3912060260772705\n",
      "------------------------ Time Elapsed: 3092.3231995105743 seconds ------------------------\n",
      "Epoch: 23 Loss D.: 0.5118042230606079\n",
      "Epoch: 23 Loss G.: 1.1272388696670532\n",
      "------------------------ Time Elapsed: 3235.5104036331177 seconds ------------------------\n",
      "Epoch: 24 Loss D.: 0.5145916938781738\n",
      "Epoch: 24 Loss G.: 2.0292413234710693\n",
      "------------------------ Time Elapsed: 3382.1801261901855 seconds ------------------------\n",
      "Epoch: 25 Loss D.: 0.3361610770225525\n",
      "Epoch: 25 Loss G.: 1.573961853981018\n",
      "------------------------ Time Elapsed: 3526.5329575538635 seconds ------------------------\n",
      "Epoch: 26 Loss D.: 0.5274782776832581\n",
      "Epoch: 26 Loss G.: 1.2123222351074219\n",
      "------------------------ Time Elapsed: 3674.5955514907837 seconds ------------------------\n",
      "Epoch: 27 Loss D.: 0.387590616941452\n",
      "Epoch: 27 Loss G.: 1.474251627922058\n",
      "------------------------ Time Elapsed: 3820.9173107147217 seconds ------------------------\n",
      "Epoch: 28 Loss D.: 0.449673056602478\n",
      "Epoch: 28 Loss G.: 1.6582492589950562\n",
      "------------------------ Time Elapsed: 3963.862646818161 seconds ------------------------\n",
      "Epoch: 29 Loss D.: 0.29236266016960144\n",
      "Epoch: 29 Loss G.: 1.4870854616165161\n",
      "------------------------ Time Elapsed: 4109.807780265808 seconds ------------------------\n",
      "Epoch: 30 Loss D.: 0.4020564556121826\n",
      "Epoch: 30 Loss G.: 1.2995884418487549\n",
      "------------------------ Time Elapsed: 4253.113480091095 seconds ------------------------\n",
      "Epoch: 31 Loss D.: 0.43468302488327026\n",
      "Epoch: 31 Loss G.: 1.36680006980896\n",
      "------------------------ Time Elapsed: 4397.939925909042 seconds ------------------------\n",
      "Epoch: 32 Loss D.: 0.5551456809043884\n",
      "Epoch: 32 Loss G.: 1.6804423332214355\n",
      "------------------------ Time Elapsed: 4542.198323965073 seconds ------------------------\n",
      "Epoch: 33 Loss D.: 0.4114711880683899\n",
      "Epoch: 33 Loss G.: 1.4669568538665771\n",
      "------------------------ Time Elapsed: 4687.125197172165 seconds ------------------------\n",
      "Epoch: 34 Loss D.: 0.40327417850494385\n",
      "Epoch: 34 Loss G.: 1.1796183586120605\n",
      "------------------------ Time Elapsed: 4833.706965446472 seconds ------------------------\n",
      "Epoch: 35 Loss D.: 0.35354089736938477\n",
      "Epoch: 35 Loss G.: 1.2918241024017334\n",
      "------------------------ Time Elapsed: 4977.837456941605 seconds ------------------------\n",
      "Epoch: 36 Loss D.: 0.47009745240211487\n",
      "Epoch: 36 Loss G.: 1.1725237369537354\n",
      "------------------------ Time Elapsed: 5121.5490000247955 seconds ------------------------\n",
      "Epoch: 37 Loss D.: 0.41279879212379456\n",
      "Epoch: 37 Loss G.: 1.3705015182495117\n",
      "------------------------ Time Elapsed: 5266.29571890831 seconds ------------------------\n",
      "Epoch: 38 Loss D.: 0.354465126991272\n",
      "Epoch: 38 Loss G.: 1.3869597911834717\n",
      "------------------------ Time Elapsed: 5411.923321485519 seconds ------------------------\n",
      "Epoch: 39 Loss D.: 0.47775471210479736\n",
      "Epoch: 39 Loss G.: 1.2866138219833374\n",
      "------------------------ Time Elapsed: 5562.063480615616 seconds ------------------------\n",
      "Epoch: 40 Loss D.: 0.45377498865127563\n",
      "Epoch: 40 Loss G.: 1.3710702657699585\n",
      "------------------------ Time Elapsed: 5708.321182966232 seconds ------------------------\n",
      "Epoch: 41 Loss D.: 0.4863734841346741\n",
      "Epoch: 41 Loss G.: 1.2568650245666504\n",
      "------------------------ Time Elapsed: 5857.144624471664 seconds ------------------------\n",
      "Epoch: 42 Loss D.: 0.4805893898010254\n",
      "Epoch: 42 Loss G.: 1.3241071701049805\n",
      "------------------------ Time Elapsed: 6008.074376344681 seconds ------------------------\n",
      "Epoch: 43 Loss D.: 0.4437544047832489\n",
      "Epoch: 43 Loss G.: 1.498823881149292\n",
      "------------------------ Time Elapsed: 6158.385042190552 seconds ------------------------\n",
      "Epoch: 44 Loss D.: 0.5323665142059326\n",
      "Epoch: 44 Loss G.: 1.5893303155899048\n",
      "------------------------ Time Elapsed: 6311.772362470627 seconds ------------------------\n",
      "Epoch: 45 Loss D.: 0.43163275718688965\n",
      "Epoch: 45 Loss G.: 1.4221374988555908\n",
      "------------------------ Time Elapsed: 6467.304845094681 seconds ------------------------\n",
      "Epoch: 46 Loss D.: 0.4049290716648102\n",
      "Epoch: 46 Loss G.: 1.3149019479751587\n",
      "------------------------ Time Elapsed: 6624.3856999874115 seconds ------------------------\n",
      "Epoch: 47 Loss D.: 0.38653090596199036\n",
      "Epoch: 47 Loss G.: 1.5034936666488647\n",
      "------------------------ Time Elapsed: 6781.631147861481 seconds ------------------------\n",
      "Epoch: 48 Loss D.: 0.6196101903915405\n",
      "Epoch: 48 Loss G.: 1.265474557876587\n",
      "------------------------ Time Elapsed: 6940.786670684814 seconds ------------------------\n",
      "Epoch: 49 Loss D.: 0.4694189131259918\n",
      "Epoch: 49 Loss G.: 1.3185393810272217\n",
      "------------------------ Time Elapsed: 7100.2563734054565 seconds ------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training using the Loop:\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epochs_cnt):\n",
    "    for n, (real_sample_set, mnist_labels) in enumerate(train_dataLoader):\n",
    "        \n",
    "        # Sending the data to device for training Discriminator\n",
    "        real_sample_set = real_sample_set.to(device=device)\n",
    "        real_sample_labels = torch.ones((batch_sz, 1)).to(device=device)\n",
    "        latent_space_samples = torch.randn((batch_sz, 100)).to(device=device)\n",
    "        \n",
    "        generated_samples = generator_(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_sz,1)).to(device=device)\n",
    "        \n",
    "        all_samples = torch.cat((real_sample_set, generated_samples))\n",
    "        all_samples_labels = torch.cat((real_sample_labels, generated_samples_labels))\n",
    "        \n",
    "        # Training the Discriminator\n",
    "        discriminator_.zero_grad()\n",
    "        output_discriminator = discriminator_(all_samples)\n",
    "        loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "        \n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        \n",
    "        # Sending the data to device for training Generator\n",
    "        latent_space_samples = torch.randn((batch_sz, 100)).to(device=device)\n",
    "        \n",
    "        # Training the Generator\n",
    "        generator_.zero_grad()\n",
    "        generated_samples = generator_(latent_space_samples)\n",
    "        output_discriminator_generated = discriminator_(generated_samples)\n",
    "        loss_generator = loss_function(output_discriminator_generated, real_sample_labels)\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        # Show loss\n",
    "        if n == batch_sz-1:\n",
    "            print(\"Epoch: {} Loss D.: {}\".format(epoch, loss_discriminator))\n",
    "            print(\"Epoch: {} Loss G.: {}\".format(epoch, loss_generator))\n",
    "            print(\"------------------------ Time Elapsed: {} seconds ------------------------\".format(end-start))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e1b34",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b254c",
   "metadata": {},
   "source": [
    "## Generated Samples Verifying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c96eee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.9987, -1.0000, -1.0000,  ..., -1.0000, -0.9996, -0.9810],\n",
      "          [-1.0000, -0.9998, -0.9995,  ..., -0.9999, -0.9998, -1.0000],\n",
      "          [-1.0000, -1.0000, -0.9994,  ..., -0.9987, -0.9681, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9999, -0.9894, -0.9976],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9998, -1.0000, -0.9870],\n",
      "          [-1.0000, -1.0000, -0.9999,  ..., -0.9996, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9999, -0.9996, -1.0000,  ..., -1.0000, -1.0000, -0.9999],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -0.9990, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9940, -1.0000, -1.0000]]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "latent_space_samples = torch.randn(batch_sz, 100).to(device=device)\n",
    "generated_samples = generator_(latent_space_samples)\n",
    "print(generated_samples[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa4c02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detaching data from CPU/GPU\n",
    "\n",
    "generated_samples = generated_samples.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ac47fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Generated Samples to file\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.save(\"generated_samples.npy\", generated_samples.numpy())\n",
    "# for fetching from \"generated_samples.npy\" file\n",
    "# arr = np.load('generated_samples.npy')\n",
    "\n",
    "\n",
    "np.savetxt(\"generated_samples.txt\", generated_samples.numpy().flatten())\n",
    "# for fetching from \"generated_samples.txt\" file\n",
    "# arr = np.loadtxt('generated_samples.txt')\n",
    "# reshape the array to its original shape\n",
    "# arr = arr.reshape((2, 3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e5574b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9987, -1.0000, -1.0000,  ..., -1.0000, -0.9996, -0.9810],\n",
       "          [-1.0000, -0.9998, -0.9995,  ..., -0.9999, -0.9998, -1.0000],\n",
       "          [-1.0000, -1.0000, -0.9994,  ..., -0.9987, -0.9681, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -0.9999, -0.9894, -0.9976],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -0.9998, -1.0000, -0.9870],\n",
       "          [-1.0000, -1.0000, -0.9999,  ..., -0.9996, -1.0000, -1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.9999, -0.9996, -1.0000,  ..., -1.0000, -1.0000, -0.9999],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -0.9990, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -0.9940, -1.0000, -1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-1.0000, -0.9999, -0.9996,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -0.9997,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -0.9993, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-0.9999, -1.0000, -0.9992,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.0000, -0.9997, -0.9998,  ..., -0.9998, -0.9997, -0.9993],\n",
       "          [-0.9972, -0.9994, -0.9939,  ..., -0.9993, -0.9999, -1.0000],\n",
       "          [-0.9995, -0.9999, -0.9966,  ..., -0.9999, -1.0000, -0.9997],\n",
       "          ...,\n",
       "          [-0.9997, -1.0000, -0.9996,  ..., -0.9993, -1.0000, -0.9999],\n",
       "          [-0.9999, -0.9999, -0.9983,  ..., -0.9573, -0.9899, -0.9911],\n",
       "          [-0.9998, -0.9998, -0.9992,  ..., -0.9986, -0.9999, -1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-1.0000, -0.9981, -0.9981,  ..., -0.9909, -0.9893, -0.9999],\n",
       "          [-0.9289, -0.6852, -0.9980,  ..., -1.0000, -1.0000, -0.9996],\n",
       "          [-0.9777, -0.9997, -0.9971,  ..., -1.0000, -0.9941, -0.9999],\n",
       "          ...,\n",
       "          [-1.0000, -0.9980, -0.9998,  ..., -0.9999, -0.9999, -1.0000],\n",
       "          [-0.9999, -0.9570, -0.9243,  ..., -0.9981, -0.9999, -0.7567],\n",
       "          [-0.9996, -0.9999, -0.9999,  ..., -0.9999, -0.9999, -1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.9999, -0.9996, -0.9994,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -0.9992,  ..., -1.0000, -0.9998, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -0.9905, -1.0000,  ..., -1.0000, -0.9998, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-0.9968, -0.9999, -0.9999,  ..., -1.0000, -1.0000, -1.0000]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fa9dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exporting Trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e8a21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generator Model\n",
    "torch.save(generator_.state_dict(), 'generator_model.pth')\n",
    "\n",
    "# Save the discriminator Model\n",
    "torch.save(discriminator_.state_dict(), 'discriminator_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec35caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved models\n",
    "gen_model = torch.load('generator_model.pth')\n",
    "disc_model = torch.load('discriminator_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47e78b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272181b4",
   "metadata": {},
   "source": [
    "## Plotting Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plt.imshow(generated_samples[i].reshape(28,28), cmap='gray_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ca91c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6fbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
